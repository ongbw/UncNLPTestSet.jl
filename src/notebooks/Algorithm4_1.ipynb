{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "using UncNLPTestSet\n",
    "using DiffResults\n",
    "using ForwardDiff: Dual, Partials, value, partials\n",
    "using LinearAlgebra\n",
    "nlp = SelectProgram(\"SROSENBR\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "┌ Info: Precompiling UncNLPTestSet [ac41c6d5-581c-4fd8-9896-caf0766f302e]\n",
      "└ @ Base loading.jl:1342\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Debug BDQRTIC\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/BDQRTIC.jl:73\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Issue in CUTEst? See comment https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl/blob/main/src/broydn7d.jl#L50 \n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/BROYDN7D.jl:109\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Issue in CUTEst? See https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl/blob/main/src/brybnd.jl\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/BRYBND.jl:110\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Debug CRAGGLVY\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/CRAGGLVY.jl:75\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Clean up DIXMAANB (and others) implementation. See comment block\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/DIXMAANB.jl:108\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Implement DIXON3DQ\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/DIXON3DQ.jl:1\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Implement DQRTIC\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/DQRTIC.jl:1\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Debug EDENSCH\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/EDENSCH.jl:60\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: FLETCHCR, determine starting iterate - see whiteboard\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/FLETCHCR.jl:52\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Implement FLEUROTH\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/FREUROTH.jl:1\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Implement GENROSE\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/GENROSE.jl:1\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Figure out why LANGER doesn't have an SIF but in Princeton and Georgian repo\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/LANGER.jl:23\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Implement MOREBV\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/MOREBV.jl:1\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Implement NONCVXU2\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/NONCVXU2.jl:1\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: Debug PENALTY2\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/PENALTY2.jl:77\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTODO: verify power_corrected.jl formula matches Oren's specification\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/power_corrected.jl:15\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mpower_corrected: Currently excluded, but maybe include after testing?\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ UncNLPTestSet ~/.julia/dev/UncNLPTestSet/src/problems/power_corrected.jl:47\u001b[39m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We illustrate overloading our objective function of the Seperable Rosenbrock problem with a Dual number, which returns a tuple containing two fields.\n",
    "- objDual.value: the value of the objective function at the specified point (nlp.x0)\n",
    "- objDual.partials: the derivative of the objective function in the specified direction (v1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "v1 = rand(nlp.n)\n",
    "objDual = obj(nlp, Dual{1}.(nlp.x0, v1)) \n",
    "objDual.value ≈ obj(nlp, nlp.x0), objDual.partials[1] ≈ grad(nlp, nlp.x0)'v1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(true, true)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It behaves just like we wanted. We evaluated the objective function and the specified directional derivative in an economical fasion.\n",
    "\n",
    "Now we extend this to the analytically specified gradient, to obtain curvature information of our objective function in a specified direction. (In our example, we choose a rand direction v1)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "v1 = rand(nlp.n)\n",
    "dual = Dual{2}.(nlp.x0, v1)\n",
    "g_dual = similar(dual)\n",
    "nlp.g!(g_dual, dual)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5000-element Vector{Dual{2, Float64, 1}}:\n",
       " Dual{2}(211.59999999999997,-67.74942322895767)\n",
       " Dual{2}(-87.99999999999999,38.090239918829774)\n",
       " Dual{2}(211.59999999999997,246.63867907462208)\n",
       " Dual{2}(-87.99999999999999,-77.08775560430045)\n",
       " Dual{2}(211.59999999999997,297.9407826229751)\n",
       " Dual{2}(-87.99999999999999,-98.89370713671946)\n",
       " Dual{2}(211.59999999999997,-433.5139939947571)\n",
       " Dual{2}(-87.99999999999999,181.62071436985482)\n",
       " Dual{2}(211.59999999999997,109.80785464118964)\n",
       " Dual{2}(-87.99999999999999,-30.015814959615984)\n",
       " Dual{2}(211.59999999999997,-56.170875405869715)\n",
       " Dual{2}(-87.99999999999999,37.20476264749931)\n",
       " Dual{2}(211.59999999999997,79.2059452863353)\n",
       "           ⋮\n",
       " Dual{2}(211.59999999999997,732.0640959216609)\n",
       " Dual{2}(-87.99999999999999,-250.1364377523203)\n",
       " Dual{2}(211.59999999999997,239.83901620838463)\n",
       " Dual{2}(-87.99999999999999,-81.74825445079945)\n",
       " Dual{2}(211.59999999999997,-62.05852661016894)\n",
       " Dual{2}(-87.99999999999999,40.51650522577033)\n",
       " Dual{2}(211.59999999999997,0.08097873750042472)\n",
       " Dual{2}(-87.99999999999999,3.231386902824962)\n",
       " Dual{2}(211.59999999999997,1143.9594439732828)\n",
       " Dual{2}(-87.99999999999999,-404.3931039781011)\n",
       " Dual{2}(211.59999999999997,-347.7482890506868)\n",
       " Dual{2}(-87.99999999999999,151.50707759498476)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "function extract_partials!(p, dual, n) \n",
    "\tfor i in 1:n\n",
    "\t\tp[i, :] = dual[i].partials[:]\n",
    "\tend\n",
    "\treturn p\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "extract_partials! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "using LinearAlgebra\n",
    "h = hessAD(nlp, nlp.x0);\n",
    "p = zeros(nlp.n)\n",
    "extract_partials!(p, g_dual, nlp.n);\n",
    "h*v1 ≈ p"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, it worked in this instance as well. Their ought to be a better way of extracting the partials from the Dual. Now we build a preliminary `gAD` and the above test to a block of 10 directions.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "function gAD(nlp, x::Vector{<:Real}, S::Matrix{<:Real})\n",
    "    dual = Dual{1}.(x,  eachcol(S)...)\n",
    "    result = Dual{1}.(zeros(nlp.n),  eachcol(S)...) # TODO: this is ridiculous\n",
    "\tnlp.g!(result, dual)\n",
    "    g = similar(x)\n",
    "    for i in 1:nlp.n\n",
    "        S[i, :] = result[i].partials[:]\n",
    "        g[i] = result[i].value\n",
    "    end\n",
    "    return g, S\n",
    "end"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "gAD (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "S = rand(nlp.n, 10);\n",
    "dual = gAD(nlp, nlp.x0, S)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999  …  211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999, 211.59999999999997, -87.99999999999999], [682.32484895812 661.7034898707896 … 308.6036867290044 138.19364215961576; -242.82256207826464 -233.1344968107893 … -105.71248770383858 -40.94437696675605; … ; 553.4983515260164 -2.655990289504292 … -363.17695013230485 -125.81546902662981; -181.38644768205606 6.093763213556996 … 155.03258280533956 64.50264323844107])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We confirm that our dual contians the supplemental hessian information, that correspond to the directions of the columns of S. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "s1 = extract_partials!(similar(S), dual, nlp.n)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5000×10 Matrix{Float64}:\n",
       "  -69.3352   486.32     412.788    …   588.923    338.69       45.5174\n",
       "   31.2506  -156.496   -125.012       -202.994    -98.5139     -1.33103\n",
       "  243.166    627.332    145.98         368.179    169.542     509.994\n",
       "  -81.3048  -200.02     -29.9304      -110.604    -55.1672   -170.69\n",
       " 1094.33    1175.68    1064.0         -308.961    521.745     783.323\n",
       " -388.486   -421.993   -372.423    …   130.016   -176.112    -270.467\n",
       "   94.988    173.007    227.692        118.352     23.9639    976.765\n",
       "  -26.7531   -36.9649   -78.0801       -19.4754    -6.57908  -350.558\n",
       "  148.101    389.887    -26.5267       137.368   1188.16      537.005\n",
       "  -49.2135  -139.084     20.4594       -39.313   -421.573    -189.101\n",
       "  513.17     516.893     10.5078   …  1242.15     676.032     122.147\n",
       " -178.032   -181.485      1.13253     -444.831   -218.631     -34.9999\n",
       "  470.278    686.766    640.669        259.464    729.149      37.2278\n",
       "    ⋮                              ⋱                         \n",
       " 1014.16    1000.18     451.528       -123.256    810.288     550.033\n",
       " -357.32    -350.171   -144.686         52.1391  -279.449    -178.816\n",
       "  710.98     871.566    483.9      …  1024.7      492.629     962.066\n",
       " -253.474   -314.235   -174.447       -357.603   -174.979    -333.414\n",
       " -236.825   -175.007    265.005        366.295   1044.79      171.986\n",
       "  102.924     81.8379   -76.725       -107.822   -371.45      -35.4172\n",
       "  938.688    743.278    684.038         54.3864   702.913     891.921\n",
       " -318.542   -262.255   -231.888    …   -18.3019  -244.733    -306.49\n",
       "  979.783    507.059    411.872        122.971    184.999    -131.497\n",
       " -350.206   -172.971   -122.941        -18.8874   -62.4334     58.4061\n",
       "  399.095    106.6      685.717       1136.7        1.45318   307.014\n",
       " -143.784    -22.6008  -225.559       -403.058     17.2607    -91.8795"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "h = hessAD(nlp, nlp.x0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5000×5000 Matrix{Float64}:\n",
       " 1330.0  -480.0    -0.0    -0.0    -0.0  …    -0.0    -0.0    -0.0    -0.0\n",
       " -480.0   200.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0  1330.0  -480.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0  -480.0   200.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0  1330.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0  -480.0  …     0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0  …    -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    ⋮                                    ⋱                          \n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0  …    -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0  …     0.0     0.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0     1330.0  -480.0    -0.0    -0.0\n",
       "    0.0     0.0     0.0     0.0     0.0     -480.0   200.0     0.0     0.0\n",
       "   -0.0    -0.0    -0.0    -0.0    -0.0       -0.0    -0.0  1330.0  -480.0\n",
       "    0.0     0.0     0.0     0.0     0.0        0.0     0.0  -480.0   200.0"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "println( h*S[:, 1] ≈ s1[:, 1] )\n",
    "println( h*S[:, 2] ≈ s1[:, 2] )\n",
    "println( h*S[:, 3] ≈ s1[:, 3] )\n",
    "println( h*S[:, 4] ≈ s1[:, 4] )\n",
    "println( h*S[:, 5] ≈ s1[:, 5] )\n",
    "println( h*S[:, 6] ≈ s1[:, 6] )\n",
    "println( h*S[:, 7] ≈ s1[:, 7] )\n",
    "println( h*S[:, 8] ≈ s1[:, 8] )\n",
    "println( h*S[:, 9] ≈ s1[:, 9] )\n",
    "println( h*S[:, 10] ≈ s1[:, 10] )"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "LoadError",
     "evalue": "UndefVarError: S not defined",
     "traceback": [
      "UndefVarError: S not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "M = rand(nlp.n, 8)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "LoadError",
     "evalue": "UndefVarError: nlp not defined",
     "traceback": [
      "UndefVarError: nlp not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "file_extension": ".jl",
   "name": "julia",
   "mimetype": "application/julia",
   "version": "1.6.2"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.2",
   "language": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}